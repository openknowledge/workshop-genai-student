{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b8b6742cff65fee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GenAI Workshop\n",
    "## Lesson 1: Hello GenAI World \n",
    "\n",
    "This example is intended to familiarise you with the Jupyter notebook environment. \n",
    "\n",
    "In addition, we will build a simple first GenAi application. \n",
    "\n",
    "To do this, we proceed in 4 steps:\n",
    "\n",
    "- Step 1: Set up the environment \n",
    "- Step 2: Configure the genAI model \n",
    "- Step 3: Set up the prompt\n",
    "- Step 4: Call the model "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b938e36a3a85e97d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Set up the environment "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e600adda22789bde"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check runtime environment: "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b94c0f71909f6ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai   \n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "   COLAB = True\n",
    "   print(\"Running on COLAB environment.\") \n",
    "else:\n",
    "   COLAB = False\n",
    "   print(\"WARNING: Running on LOCAL environment.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbeeafd26f6782f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import colab specific lib to read user data (aka colab managed secrets)\n",
    "from google.colab import userdata"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e46c42368eef73ef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize Google GenAI Client API with GOOGLE_API_KEY to be able to call the model. \n",
    "# Note: GEMINI_API_KEY must be set as COLAB userdata before! \n",
    "GOOGLE_API_KEY=userdata.get('GEMINI_API_KEY')  \n",
    "genai.configure(api_key=GOOGLE_API_KEY)  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e292ed72b7fa718",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Configure the genAI model "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14034189b3eeaf1b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# set GenAI model to use \n",
    "MODEL = \"gemini-1.5-flash\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c5fe081d5c7fcbd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Set up the prompt "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50370136a90f7066"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are a friendly assistant with a preference for Germany.\"\n",
    "USER_PROMPT = \"What is the most beautiful city in the world?\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc520412a8197eeb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Call the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50e4439408134eff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.9\n",
    "MAX_OUTPUT_TOKENS = 400\n",
    "TOP_K = 2\n",
    "\n",
    "MODEL_CONFIG = genai.GenerationConfig(\n",
    "        max_output_tokens=MAX_OUTPUT_TOKENS,\n",
    "        temperature=TEMPERATURE,\n",
    "        top_k=TOP_K\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27a756b96c3e20c7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create Generative Model with the help of the genai API.\n",
    "# Use MODEL and MODEL_CONFIG as parameters\n",
    "genai_model = genai.GenerativeModel(\n",
    "    model_name=MODEL,\n",
    "    generation_config= MODEL_CONFIG\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a64a0135ef88578",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Generate response by calling the generate_content method of the genai model.\n",
    "# Use a list of SYSTEM_PROMPT and USER_PROMPT as parameters. \n",
    "response = genai_model.generate_content([SYSTEM_PROMPT, USER_PROMPT])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d831629c07bdc7e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# print out summary of input values / parameters \n",
    "print(f'SYSTEM PROMPT used:\\n {SYSTEM_PROMPT}')\n",
    "print(f'USER PROMPT used:\\n {USER_PROMPT}')\n",
    "print(f'MODEL used:\\n {MODEL} (temperature = {TEMPERATURE}, top_k = {TOP_K}, max_output_tokens = {MAX_OUTPUT_TOKENS})')\n",
    "\n",
    "# print out answer of genai model (aka text of response) \n",
    "print(f'\\nANSWER of genAI model: \\n')\n",
    "print(response.text) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e19fdd4224933606",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for all the details of the response see \n",
    "print(f'\\nTOTAL RESPONSE of genAI model: \\n')\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f346e9198452b9f6",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
