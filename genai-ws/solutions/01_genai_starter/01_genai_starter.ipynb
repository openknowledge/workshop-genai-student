{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b8b6742cff65fee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GenAI Workshop\n",
    "## Lesson 2: GenAI Starter \n",
    "\n",
    "This example is intended to play around with models and prompts. \n",
    "During this example you will learn how to ...\n",
    "\n",
    "- use diverse roles for prompting\n",
    "- apply different prompting patterns \n",
    "- manipulate the model completion via model parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b938e36a3a85e97d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set up the environment "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e600adda22789bde"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check runtime environment: "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b94c0f71909f6ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai   \n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "   COLAB = True\n",
    "   print(\"Running on COLAB environment.\") \n",
    "else:\n",
    "   COLAB = False\n",
    "   print(\"WARNING: Running on LOCAL environment.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbeeafd26f6782f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import colab specific lib to read user data (aka colab managed secrets)\n",
    "# from google.colab import userdata"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e46c42368eef73ef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize Google GenAI Client API with GOOGLE_API_KEY to be able to call the model. \n",
    "# Note: GEMINI_API_KEY must be set as COLAB userdata before! \n",
    "GOOGLE_API_KEY=userdata.get('GEMINI_API_KEY')  \n",
    "genai.configure(api_key=GOOGLE_API_KEY)  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e292ed72b7fa718",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# set default values for model, model parameters and prompt\n",
    "DEFAULT_MODEL = \"gemini-1.5-flash\"\n",
    "DEFAULT_CONFIG_TEMPERATURE = 0.9 \n",
    "DEFAULT_CONFIG_TOP_K = 1\n",
    "DEFAULT_CONFIG_MAX_OUTPUT_TOKENS = 200 \n",
    "DEFAULT_SYSTEM_PROMPT = \"Your are a friendly assistant\"\n",
    "DEFAULT_USER_PROMPT:str = \"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e72d2b967a864f4c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bee82e5c07ded99"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def call_genai_model_for_completion(\n",
    "        model_name: str = DEFAULT_MODEL, \n",
    "        config_temperature:float = DEFAULT_CONFIG_TEMPERATURE,\n",
    "        config_top_k: int = DEFAULT_CONFIG_TOP_K, \n",
    "        config_max_output_tokens: int = DEFAULT_CONFIG_MAX_OUTPUT_TOKENS, \n",
    "        system_prompt : str = DEFAULT_SYSTEM_PROMPT, \n",
    "        user_prompt : str = DEFAULT_USER_PROMPT,\n",
    "        verbose: bool = False\n",
    "        ): \n",
    "    \n",
    "    if verbose: \n",
    "        # print out summary of input values / parameters\n",
    "        print(f'Generating answer for following config:')\n",
    "        print(f'  - SYSTEM PROMPT used:\\n {system_prompt}')\n",
    "        print(f'  - USER PROMPT used:\\n {user_prompt}')\n",
    "        print(f'  - MODEL used:\\n {model_name} (temperature = {config_temperature}, top_k = {config_top_k}, max_output_tokens = {config_max_output_tokens})')\n",
    "\n",
    "    # create generation config \n",
    "    model_config = genai.GenerationConfig(\n",
    "        max_output_tokens=config_max_output_tokens,\n",
    "        temperature=config_temperature,\n",
    "        top_k=config_top_k\n",
    "    )\n",
    "    \n",
    "    # create genai model with generation config \n",
    "    genai_model = genai.GenerativeModel(\n",
    "        model_name= model_name,\n",
    "        generation_config= model_config\n",
    "    )\n",
    "    \n",
    "    response = genai_model.generate_content([system_prompt, user_prompt])\n",
    "    return response; "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8ec0540c47fd175",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def print_completion_result(completion_result, full:bool = False):\n",
    "        \n",
    "    # print out answer of genai model (aka text of response) \n",
    "    print(f'\\nANSWER of genAI model: \\n')\n",
    "    if full:\n",
    "        print(completion_result)\n",
    "    else: \n",
    "        print(completion_result.text) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f46449b2da08c3c5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 01: Prompting with roles \n",
    "\n",
    "During this exercise you will ..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14034189b3eeaf1b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "user_prompt = \"What is the most beautiful city in the world?\"\n",
    "system_prompt = \"You are a friendly assistant with a preference for Germany.\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52940e4e56fb425f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 1: call genai model without any prompts\n",
    "response = call_genai_model_for_completion()\n",
    "print_completion_result(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99ba098493020806",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 2: call genai model with user prompt only\n",
    "response = call_genai_model_for_completion(user_prompt=user_prompt)\n",
    "print_completion_result(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee190ebf1f6260c5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 2: call genai model with system and user prompt\n",
    "response = call_genai_model_for_completion(system_prompt=system_prompt, user_prompt=user_prompt)\n",
    "print_completion_result(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89e423141c25fc76",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 02: Prompting patterns and best practices\n",
    "\n",
    "During this exercise you will ..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dcd0c8b9529083b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prompt parts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dcfbfa5b96996f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d65f6bd90cdb650d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chain of Thoughts "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b7286d90b642357"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4b97ae16dbc4122"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Few Shot Learning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a782178c771a88b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " # TODO "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19f1b394d8d81077"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ### Exercise 03: Models and parameters\n",
    "\n",
    "During this exercise you will ..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dc44c1ab22b3056"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO \n",
    "# - temperature \n",
    "# - top-k\n",
    "# - max output tokens "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd81467de62fe661"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 04: Augmention \n",
    "\n",
    "During this exercise you will ..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "377d0d387e5c7ac8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#TODO\n",
    "# - add pdf(s)\n",
    "# see https://ai.google.dev/gemini-api/docs/document-processing?hl=de&lang=python"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc8bb0361401f655"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
